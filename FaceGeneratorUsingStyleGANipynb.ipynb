{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of style_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIabOSPhYgTD"
      },
      "source": [
        "# Generating High Rez GAN Faces with Google CoLab\n",
        "\n",
        "This notebook demonstrates how to run [NVidia StyleGAN](https://github.com/NVlabs/stylegan) inside of a Google CoLab notebook.  I suggest you use this to generate GAN faces from a pretrained model.  If you try to train your own, you will run into compute limitations of Google CoLab.\n",
        "\n",
        "Make sure to run this code on a GPU instance.  GPU is assumed.\n",
        "\n",
        "This is from my [class on deep learning](  https://www.youtube.com/watch?v=EQ38k6z2aks&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
        "\n",
        "[Jeff Heaton](https://www.heatonresearch.com/)\n",
        "\n",
        "# Instructions\n",
        "\n",
        "First, map your G-Drive, this is where your GANs will be written to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv7PBBU7kOkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821c87fe-83d1-49fc-e148-903f087e2af6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX4LsOo_YstE"
      },
      "source": [
        "Next, clone Stylegan from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjDcs9Wvhk_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89525a12-b264-4611-a98a-1d9916c668e5"
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Total 83 (delta 0), reused 0 (delta 0), pack-reused 83\u001b[K\n",
            "Unpacking objects: 100% (83/83), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhGqVIl8Y1m1"
      },
      "source": [
        "Verify that Stylegan has been cloned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TQMXLBNjoV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cda299c-5273-4104-916b-33af50945610"
      },
      "source": [
        "!ls /content/stylegan/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config.py\t     LICENSE.txt\t    run_metrics.py\n",
            "dataset_tool.py      metrics\t\t    stylegan-teaser.png\n",
            "dnnlib\t\t     pretrained_example.py  training\n",
            "generate_figures.py  README.md\t\t    train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zARjPp4rY6vc"
      },
      "source": [
        "Add the Stylegan folder to Python so that you can import it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6YsEVRKPIBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690aa885-ef07-483c-8ceb-b06d5808a8e0"
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.35.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.33.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (50.3.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=5ab16c0130c57e906332db31f6363fae0a3e6b076f0d0b8234136bc752d6f1a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, keras-applications, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaFXI2RMhmly"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/stylegan\")\n",
        "\n",
        "import dnnlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxmjqpxdZFkj"
      },
      "source": [
        "The code below is baed on code from NVidia.  This actually generates your images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfN_qgXVi2PU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa16f018-7c1d-4f74-9b7a-b80c17517380"
      },
      "source": [
        "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n",
        "#\n",
        "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "# 4.0 International License. To view a copy of this license, visit\n",
        "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\n",
        "\"\"\"Minimal script for generating an image using pre-trained StyleGAN generator.\"\"\"\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "\n",
        "def main():\n",
        "    # Initialize TensorFlow.\n",
        "    tflib.init_tf()\n",
        "#https://drive.google.com/file/d/1MGqJl28pN4t7SAtSrPdSRJSQJqahkzUf/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1hySuVWqediV9x3EzkHK8oHp3xo_ynZqd/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1hySuVWqediV9x3EzkHK8oHp3xo_ynZqd/view?usp=sharing\n",
        "    # Load pre-trained network.\n",
        "    url = 'https://drive.google.com/uc?id=1hySuVWqediV9x3EzkHK8oHp3xo_ynZqd' # karras2019stylegan-ffhq-1024x1024.pkl\n",
        "    with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
        "        _G, _D, Gs = pickle.load(f)\n",
        "        # _G = Instantaneous snapshot of the generator. Mainly useful for resuming a previous training run.\n",
        "        # _D = Instantaneous snapshot of the discriminator. Mainly useful for resuming a previous training run.\n",
        "        # Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.\n",
        "\n",
        "    # Print network details.\n",
        "    Gs.print_layers()\n",
        "\n",
        "    # Pick latent vector.\n",
        "    rnd = np.random.RandomState()\n",
        "    \n",
        "\n",
        "    latents = rnd.randn(1, Gs.input_shape[1])\n",
        "\n",
        "    # Generate image.\n",
        "    fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)\n",
        "\n",
        "    # Save image.\n",
        "    os.makedirs(config.result_dir, exist_ok=True)\n",
        "    png_filename = os.path.join(config.result_dir, f'/content/drive/My Drive/example3.png')\n",
        "    PIL.Image.fromarray(images[0], 'RGB').save(png_filename)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Gs                              Params    OutputShape          WeightShape     \n",
            "---                             ---       ---                  ---             \n",
            "latents_in                      -         (?, 512)             -               \n",
            "labels_in                       -         (?, 0)               -               \n",
            "lod                             -         ()                   -               \n",
            "dlatent_avg                     -         (512,)               -               \n",
            "G_mapping/latents_in            -         (?, 512)             -               \n",
            "G_mapping/labels_in             -         (?, 0)               -               \n",
            "G_mapping/PixelNorm             -         (?, 512)             -               \n",
            "G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense2                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense3                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense4                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense5                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense6                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense7                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Broadcast             -         (?, 18, 512)         -               \n",
            "G_mapping/dlatents_out          -         (?, 18, 512)         -               \n",
            "Truncation                      -         (?, 18, 512)         -               \n",
            "G_synthesis/dlatents_in         -         (?, 18, 512)         -               \n",
            "G_synthesis/4x4/Const           534528    (?, 512, 4, 4)       (512,)          \n",
            "G_synthesis/4x4/Conv            2885632   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod8          1539      (?, 3, 4, 4)         (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up        2885632   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1           2885632   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod7          1539      (?, 3, 8, 8)         (1, 1, 512, 3)  \n",
            "G_synthesis/Upscale2D           -         (?, 3, 8, 8)         -               \n",
            "G_synthesis/Grow_lod7           -         (?, 3, 8, 8)         -               \n",
            "G_synthesis/16x16/Conv0_up      2885632   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1         2885632   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod6          1539      (?, 3, 16, 16)       (1, 1, 512, 3)  \n",
            "G_synthesis/Upscale2D_1         -         (?, 3, 16, 16)       -               \n",
            "G_synthesis/Grow_lod6           -         (?, 3, 16, 16)       -               \n",
            "G_synthesis/32x32/Conv0_up      2885632   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1         2885632   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/ToRGB_lod5          1539      (?, 3, 32, 32)       (1, 1, 512, 3)  \n",
            "G_synthesis/Upscale2D_2         -         (?, 3, 32, 32)       -               \n",
            "G_synthesis/Grow_lod5           -         (?, 3, 32, 32)       -               \n",
            "G_synthesis/64x64/Conv0_up      1442816   (?, 256, 64, 64)     (3, 3, 512, 256)\n",
            "G_synthesis/64x64/Conv1         852992    (?, 256, 64, 64)     (3, 3, 256, 256)\n",
            "G_synthesis/ToRGB_lod4          771       (?, 3, 64, 64)       (1, 1, 256, 3)  \n",
            "G_synthesis/Upscale2D_3         -         (?, 3, 64, 64)       -               \n",
            "G_synthesis/Grow_lod4           -         (?, 3, 64, 64)       -               \n",
            "G_synthesis/128x128/Conv0_up    426496    (?, 128, 128, 128)   (3, 3, 256, 128)\n",
            "G_synthesis/128x128/Conv1       279040    (?, 128, 128, 128)   (3, 3, 128, 128)\n",
            "G_synthesis/ToRGB_lod3          387       (?, 3, 128, 128)     (1, 1, 128, 3)  \n",
            "G_synthesis/Upscale2D_4         -         (?, 3, 128, 128)     -               \n",
            "G_synthesis/Grow_lod3           -         (?, 3, 128, 128)     -               \n",
            "G_synthesis/256x256/Conv0_up    139520    (?, 64, 256, 256)    (3, 3, 128, 64) \n",
            "G_synthesis/256x256/Conv1       102656    (?, 64, 256, 256)    (3, 3, 64, 64)  \n",
            "G_synthesis/ToRGB_lod2          195       (?, 3, 256, 256)     (1, 1, 64, 3)   \n",
            "G_synthesis/Upscale2D_5         -         (?, 3, 256, 256)     -               \n",
            "G_synthesis/Grow_lod2           -         (?, 3, 256, 256)     -               \n",
            "G_synthesis/512x512/Conv0_up    51328     (?, 32, 512, 512)    (3, 3, 64, 32)  \n",
            "G_synthesis/512x512/Conv1       42112     (?, 32, 512, 512)    (3, 3, 32, 32)  \n",
            "G_synthesis/ToRGB_lod1          99        (?, 3, 512, 512)     (1, 1, 32, 3)   \n",
            "G_synthesis/Upscale2D_6         -         (?, 3, 512, 512)     -               \n",
            "G_synthesis/Grow_lod1           -         (?, 3, 512, 512)     -               \n",
            "G_synthesis/1024x1024/Conv0_up  21056     (?, 16, 1024, 1024)  (3, 3, 32, 16)  \n",
            "G_synthesis/1024x1024/Conv1     18752     (?, 16, 1024, 1024)  (3, 3, 16, 16)  \n",
            "G_synthesis/ToRGB_lod0          51        (?, 3, 1024, 1024)   (1, 1, 16, 3)   \n",
            "G_synthesis/Upscale2D_7         -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/Grow_lod0           -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/images_out          -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/lod                 -         ()                   -               \n",
            "G_synthesis/noise0              -         (1, 1, 4, 4)         -               \n",
            "G_synthesis/noise1              -         (1, 1, 4, 4)         -               \n",
            "G_synthesis/noise2              -         (1, 1, 8, 8)         -               \n",
            "G_synthesis/noise3              -         (1, 1, 8, 8)         -               \n",
            "G_synthesis/noise4              -         (1, 1, 16, 16)       -               \n",
            "G_synthesis/noise5              -         (1, 1, 16, 16)       -               \n",
            "G_synthesis/noise6              -         (1, 1, 32, 32)       -               \n",
            "G_synthesis/noise7              -         (1, 1, 32, 32)       -               \n",
            "G_synthesis/noise8              -         (1, 1, 64, 64)       -               \n",
            "G_synthesis/noise9              -         (1, 1, 64, 64)       -               \n",
            "G_synthesis/noise10             -         (1, 1, 128, 128)     -               \n",
            "G_synthesis/noise11             -         (1, 1, 128, 128)     -               \n",
            "G_synthesis/noise12             -         (1, 1, 256, 256)     -               \n",
            "G_synthesis/noise13             -         (1, 1, 256, 256)     -               \n",
            "G_synthesis/noise14             -         (1, 1, 512, 512)     -               \n",
            "G_synthesis/noise15             -         (1, 1, 512, 512)     -               \n",
            "G_synthesis/noise16             -         (1, 1, 1024, 1024)   -               \n",
            "G_synthesis/noise17             -         (1, 1, 1024, 1024)   -               \n",
            "images_out                      -         (?, 3, 1024, 1024)   -               \n",
            "---                             ---       ---                  ---             \n",
            "Total                           26219627                                       \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzqJGX1Gj_fn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12475f41-f379-4f36-b429-d0fec35c3578"
      },
      "source": [
        "!ls /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 5079.pdf\n",
            " Accenture\n",
            " app-1.apk\n",
            " app-debug.apk\n",
            " app-debug_test.apk\n",
            " ASU\n",
            "'BANK PROOF'\n",
            "'Copy of karras2019stylegan-celebahq-1024x1024 (1).pkl'\n",
            "'Copy of karras2019stylegan-celebahq-1024x1024.pkl'\n",
            "'Copy of karras2019stylegan-ffhq-1024x1024.pkl'\n",
            " Documents\n",
            " example1.png\n",
            " eyesight.pdf\n",
            "'FSE Jared summer.gsheet'\n",
            "'full time.gsheet'\n",
            "'IELTS N GRE'\n",
            "'intern_cover letter.pdf'\n",
            " internship\n",
            " Internship_resume\n",
            "'Internship Resume'\n",
            "'late submissions.gsheet'\n",
            " License.pdf\n",
            "'Licience_plate_reco (1).rar'\n",
            " Licience_plate_reco.rar\n",
            "'Lors final list'\n",
            "'Machine learning'\n",
            "'Mac Upload'\n",
            "'nanamma photos'\n",
            " Nirdesh_documents_parttime\n",
            " nirdeshmun2016\n",
            "'Nirdesh Resume  (1).gdoc'\n",
            "'Nirdesh Resume .docx'\n",
            "'Nirdesh Resume .gdoc'\n",
            "'Nova GRE math bible.pdf'\n",
            "'Number Plate Recognition'\n",
            " Numberplaterecognition.zip\n",
            " Parttime\n",
            " Princeton\n",
            "'Puppy sister marriage'\n",
            " Report.gdoc\n",
            " Resume\n",
            "'Resume (1).gdoc'\n",
            " Resume.gdoc\n",
            " RESUME_INTERN.pdf\n",
            "'Resume Template.doc'\n",
            "'Resume Template.gdoc'\n",
            " Rsaragwal\n",
            " saicharan_july21-SubLease_React-master.zip\n",
            "'Sanjay resume'\n",
            "'Sensagrate Employee CIIAA_Nirdesh Konireddy.gdoc'\n",
            "'Sensagrate Employee CIIAA_Nirdesh Konireddy.pdf'\n",
            "'SOP AND LOR'\n",
            " test.apk\n",
            " Transcripts\n",
            " Transcripts.pdf\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document (2).gdoc'\n",
            "'Untitled document.gdoc'\n",
            " VISA\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}